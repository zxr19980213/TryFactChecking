{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer,BertModel\n",
    "import logging\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_withGoldenLabel`为人工标注标签\n",
    "\n",
    "`data_withSilverLabel`为算法标注标签\n",
    "\n",
    "`data`去重:重复数据直接删除\n",
    "\n",
    "将`author`中`nan`替换为`'Not Available'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_table(\"./DataSet/book/book.txt\" , sep='\\t' , header=None , names=['source','isbn','name','author'])\n",
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "data.fillna('Not Available', inplace=True)\n",
    "data['encode']=None\n",
    "GoldenLabel = pd.read_table(\"./DataSet/book/book_golden.txt\" , sep='\\t' , header=None , names=['isbn','author'])\n",
    "SilverLabel = pd.read_table(\"./DataSet/book/book_silver.txt\" , sep='\\t' , header=None , names=['isbn','author'])\n",
    "SilverLabel = SilverLabel[SilverLabel['isbn']!='F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载`bert`模型和分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处逐条处理数据，后期考虑封装成`Processor`\n",
    "\n",
    "将每条数据的三部分拼接向量化还是分别向量化？\n",
    "\n",
    "选用`[CLS]`的最后一个隐层编码\n",
    "\n",
    "GPU内存不足，暂定在CPU上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(data)):\n",
    "    item = data.loc[i]\n",
    "    text = '[CLS] ' + (item['source']) + ' [SEP] ' + (item['name']) + ' [SEP] ' + (item['author']) + ' [SEP]'\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    #torch.cuda.empty_cache()\n",
    "    #model.to('cuda')\n",
    "    #tokens_tensor = tokens_tensor.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        encoded_layers,_ = model(tokens_tensor)\n",
    "    data.loc[i]['encode'] = encoded_layers[11][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储中间结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save( data['encode'] , './DataSet/book/claims_encode.pt' )\n",
    "data['encode'] = None\n",
    "data.to_csv( './DataSet/book/claims.txt' , sep='\\t' , index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取中间结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = None\n",
    "data = pd.read_csv( \"./DataSet/book/claims.txt\" , sep='\\t' )\n",
    "#n_data['source'] = n_data['source'].astype(str)\n",
    "#n_data['isbn'] = n_data['isbn'].astype(str)\n",
    "#n_data['name'] = n_data['name'].astype(str)\n",
    "#n_data['author'] = n_data['author'].astype(str)\n",
    "data['encode'] = torch.load(\"./DataSet/book/claims_encode.pt\")\n",
    "GoldenLabel = pd.read_table(\"./DataSet/book/book_golden.txt\" , sep='\\t' , header=None , names=['isbn','author'])\n",
    "SilverLabel = pd.read_table(\"./DataSet/book/book_silver.txt\" , sep='\\t' , header=None , names=['isbn','author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里讨巧使用`difflib`来度量字符串相似度，相似度的阈值后期可调，发现字符串肉眼相似但相似度量极低的情况！考虑第三方库的字符串相似度量？\n",
    "\n",
    "后续可能需要改进，考虑再次引入`bert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['label'] = None\n",
    "data['label'] = data['label'].astype(bool)\n",
    "data_golden = pd.DataFrame(data.drop(data.index,inplace=False))\n",
    "\n",
    "for index1,row1 in GoldenLabel.iterrows():\n",
    "    str1 = row1['author'].lower()\n",
    "    data_goldenSlice = pd.DataFrame(data[data['isbn']==row1['isbn']])\n",
    "    for index2,row2 in data_goldenSlice.iterrows():\n",
    "        str2 = row2['author'].lower()\n",
    "        data_goldenSlice.loc[index2,'label'] = (difflib.SequenceMatcher(None,str1,str2).quick_ratio()>0.8)\n",
    "    data_golden = data_golden.append(data_goldenSlice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储中间结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_golden.reset_index(drop=True,inplace=True)\n",
    "torch.save( data_golden['encode'] , './DataSet/book/golden/claims_golden_encode.pt' )\n",
    "data_golden['encode'] = None\n",
    "data_golden.to_csv( './DataSet/book/golden/claims_golden.txt' , sep='\\t' , index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取中间结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_golden = pd.read_csv( './DataSet/book/golden/claims_golden.txt' , sep='\\t' )\n",
    "data_golden['encode'] = torch.load('./DataSet/book/golden/claims_golden_encode.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "book_silver.txt数据集有点问题，下一块代码暂且搁置\n",
    "\n",
    "这个`book`数据集问题很大，值得吐槽；`dataset`中存在大量冗余数据；golden中存在两条`isbn`为`F`的奇怪数据；`silver`中许多数据`isbn`和`dataset`对应不上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "data['label'] = None\n",
    "data['label'] = data['label'].astype(bool)\n",
    "data_silver = pd.DataFrame(data.drop(data.index,inplace=False))\n",
    "\n",
    "for index1,row1 in SilverLabel.iterrows():\n",
    "    str1 = row1['author'].lower()\n",
    "    data_silverSlice = pd.DataFrame(data[data['isbn']==row1['isbn']])\n",
    "    for index2,row2 in data_silverSlice.iterrows():\n",
    "        str2 = row2['author'].lower()\n",
    "        data_silverSlice.loc[index2,'label'] = (difflib.SequenceMatcher(None,str1,str2).quick_ratio()>0.8)\n",
    "    data_silver = data_silver.append(data_silverSlice)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_gpu]",
   "language": "python",
   "name": "conda-env-pytorch_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
