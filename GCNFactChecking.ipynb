{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import difflib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#来自DGLGraph tutorial\n",
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        #self.conv = nn.Conv1d(in_feats,out_feats,1)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        #h = self.conv(node.data['h'])\n",
    "        h = self.linear(node.data['h'])\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        return {'h' : h}\n",
    "\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN(768, 384, F.relu)\n",
    "        self.gcn2 = GCN(384, 192, F.relu)\n",
    "        self.fc = nn.Linear(192, 2)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        x = self.gcn2(g, x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, g, features):\n",
    "        pred = F.softmax(self.forward(g, features))\n",
    "        ans = []\n",
    "        for t in pred:\n",
    "            if t[0]>t[1]:\n",
    "                ans.append(0)\n",
    "            else:\n",
    "                ans.append(1)\n",
    "        return torch.tensor(ans)\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取DealWithData中golden数据\n",
    "data_golden = pd.read_csv( './DataSet/book/golden/claims_golden.txt' , sep='\\t' )\n",
    "data_golden['encode'] = torch.load('./DataSet/book/golden/claims_golden_encode.pt')\n",
    "GoldenLabel = pd.read_table(\"./DataSet/book/book_golden.txt\" , sep='\\t' , header=None , names=['isbn','author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#随意点划分训练集和测试集，直觉要根据'isbn'划分 -> 改为不直接划分数据集，采用mask方式划分\n",
    "'''\n",
    "data_train = pd.DataFrame(data_golden.drop(data_golden.index,inplace=False))\n",
    "data_test = pd.DataFrame(data_golden.drop(data_golden.index,inplace=False))\n",
    "for i in range(0,int(len(GoldenLabel)/2+1)):\n",
    "    data_trainSlice = data_golden[data_golden['isbn']==GoldenLabel.loc[i]['isbn']]\n",
    "    data_train = data_train.append(data_trainSlice)\n",
    "for i in range(int(len(GoldenLabel)/2+1),len(GoldenLabel)):\n",
    "    data_testSlice = data_golden[data_golden['isbn']==GoldenLabel.loc[i]['isbn']]\n",
    "    data_test = data_test.append(data_testSlice)\n",
    "data_train.reset_index(drop=True,inplace=True)\n",
    "data_test.reset_index(drop=True,inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide_dataset(dfw,dfk,test_ratio):\n",
    "    a = np.random.choice(len(dfk), int(len(dfk)*test_ratio), replace=False)\n",
    "    test_set = set()\n",
    "    for i in range(0,a.shape[0]):\n",
    "        test_set.add(dfk.loc[a[i]]['isbn'])\n",
    "    train_mask = torch.Tensor(size=[len(dfw)]).bool()\n",
    "    test_mask = torch.Tensor(size=[len(dfw)]).bool()\n",
    "    for i in range(0,len(dfw)):\n",
    "        if dfw.loc[i]['isbn'] in test_set:\n",
    "            test_mask[i] = True\n",
    "            train_mask[i] = False\n",
    "        else:\n",
    "            test_mask[i] = False\n",
    "            train_mask[i] = True\n",
    "    return train_mask,test_mask\n",
    "train_mask,test_mask = divide_dataset(data_golden,GoldenLabel,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(210)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构建图结构函数，根据训练集和测试集连边 -> 改为基于全体数据连边\n",
    "#此处可优化复杂度？n**2/2 -> kn\n",
    "#此处可根据'book_name'相似度进一步加边\n",
    "def generate_DGLGraph(df):\n",
    "    edge_norm = []\n",
    "    g = DGLGraph()\n",
    "    g.add_nodes(df.shape[0])\n",
    "    for i in range(0,len(df)):\n",
    "        for j in range(i+1,len(df)):\n",
    "            if (df.loc[i][\"source\"]==df.loc[j][\"source\"]):\n",
    "                g.add_edge(i,j)\n",
    "                #edge_norm.append(1.0)\n",
    "                g.add_edge(j,i)\n",
    "                #edge_norm.append(1.0)\n",
    "            elif (df.loc[i][\"isbn\"]==df.loc[j][\"isbn\"]):\n",
    "                str1 = df.loc[i]['author']\n",
    "                str2 = df.loc[j]['author']\n",
    "                #print(str1,str2,difflib.SequenceMatcher(None,str1,str2).quick_ratio())\n",
    "                if ( difflib.SequenceMatcher(None,str1,str2).quick_ratio()>0.8 ):\n",
    "                    g.add_edge(i,j)\n",
    "                    #edge_norm.append(1.0)\n",
    "                    g.add_edge(j,i)\n",
    "                    #edge_norm.append(1.0)\n",
    "    #edge_norm = torch.Tensor(edge_norm).unsqueeze(1)\n",
    "    #g.edata.update({ 'norm': edge_norm })\n",
    "    return g\n",
    "\n",
    "graph_whole = generate_DGLGraph(data_golden)\n",
    "#graph_train = generate_DGLGraph(data_train)\n",
    "#graph_test = generate_DGLGraph(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存储图结构\n",
    "file = open('./DataSet/book/golden/graph_whole.pickle', 'wb')\n",
    "pickle.dump(graph_whole, file)\n",
    "file.close()\n",
    "#file = open('./DataSet/book/golden/graph_train.pickle', 'wb')\n",
    "#pickle.dump(graph_train, file)\n",
    "#file.close()\n",
    "#file = open('./DataSet/book/golden/graph_test.pickle', 'wb')\n",
    "#pickle.dump(graph_test, file)\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载图结构\n",
    "with open('./DataSet/book/golden/graph_whole.pickle', 'rb') as file:\n",
    "    graph_whole =pickle.load(file)\n",
    "#with open('./DataSet/book/golden/graph_train.pickle', 'rb') as file:\n",
    "#    graph_train =pickle.load(file)\n",
    "#with open('./DataSet/book/golden/graph_test.pickle', 'rb') as file:\n",
    "#    graph_test =pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存储和加载图结构的失败尝试\n",
    "'''\n",
    "graph_train_netx = graph_train.to_networkx()\n",
    "graph_test_netx = graph_test.to_networkx()\n",
    "nx.write_gexf(graph_train_netx,'./DataSet/book/golden/train_graph.gexf')\n",
    "nx.write_gexf(graph_test_netx,'./DataSet/book/golden/test_graph.gexf')\n",
    "\n",
    "graph_train_netx = nx.read_gexf('./DataSet/book/golden/train_graph.gexf')\n",
    "graph_test_netx = nx.read_gexf('./DataSet/book/golden/test_graph.gexf')\n",
    "\n",
    "graph_train2 = DGLGraph(graph_train_netx)\n",
    "#graph_train2.from_networkx(graph_train_netx)\n",
    "graph_test2 = DGLGraph(graph_test_netx)\n",
    "#graph_test2.from_networkx(graph_test_netx)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_featureNlabel(df):\n",
    "    a = torch.zeros(1,768)\n",
    "    c = torch.zeros(1)\n",
    "    for _,row in df.iterrows():\n",
    "        b = row['encode'].reshape([-1,768])\n",
    "        a = torch.cat((a,b),0)\n",
    "        if(row['label']):\n",
    "            d = torch.ones(1)\n",
    "        else:\n",
    "            d = torch.zeros(1)\n",
    "        c = torch.cat((c,d),-1)\n",
    "    return a[1:,:],c[1:].long()\n",
    "whole_feature,whole_label = extract_featureNlabel(data_golden)\n",
    "#train_feature,train_label = extract_featureNlabel(data_train)\n",
    "#test_feature,test_label = extract_featureNlabel(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\acaconda\\envs\\pytorch_gpu\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 0.3381 | Time(s) 1.7750 | Train_Accu 0.838137 | Test_Accu 0.787861\n",
      "Epoch 00001 | Loss 10.4600 | Time(s) 1.7725 | Train_Accu 0.516630 | Test_Accu 0.459538\n",
      "Epoch 00002 | Loss 2.6134 | Time(s) 1.8135 | Train_Accu 0.691796 | Test_Accu 0.606936\n",
      "Epoch 00003 | Loss 4.7865 | Time(s) 1.8113 | Train_Accu 0.629712 | Test_Accu 0.669364\n",
      "Epoch 00004 | Loss 7.3724 | Time(s) 1.7989 | Train_Accu 0.607539 | Test_Accu 0.653179\n",
      "Epoch 00005 | Loss 6.8545 | Time(s) 1.7922 | Train_Accu 0.614191 | Test_Accu 0.658960\n",
      "Epoch 00006 | Loss 4.3529 | Time(s) 1.7868 | Train_Accu 0.634146 | Test_Accu 0.671676\n",
      "Epoch 00007 | Loss 0.7354 | Time(s) 1.7826 | Train_Accu 0.736142 | Test_Accu 0.732370\n",
      "Epoch 00008 | Loss 3.1127 | Time(s) 1.7807 | Train_Accu 0.680710 | Test_Accu 0.594798\n",
      "Epoch 00009 | Loss 5.1935 | Time(s) 1.7764 | Train_Accu 0.614191 | Test_Accu 0.544509\n",
      "Epoch 00010 | Loss 4.9733 | Time(s) 1.7737 | Train_Accu 0.616408 | Test_Accu 0.549711\n",
      "Epoch 00011 | Loss 2.9970 | Time(s) 1.7775 | Train_Accu 0.680710 | Test_Accu 0.602312\n",
      "Epoch 00012 | Loss 0.7689 | Time(s) 1.7927 | Train_Accu 0.813747 | Test_Accu 0.752023\n",
      "Epoch 00013 | Loss 1.6665 | Time(s) 1.8100 | Train_Accu 0.658537 | Test_Accu 0.690751\n",
      "Epoch 00014 | Loss 2.9945 | Time(s) 1.8153 | Train_Accu 0.645233 | Test_Accu 0.683237\n",
      "Epoch 00015 | Loss 3.0027 | Time(s) 1.8229 | Train_Accu 0.645233 | Test_Accu 0.683237\n",
      "Epoch 00016 | Loss 1.8835 | Time(s) 1.8229 | Train_Accu 0.658537 | Test_Accu 0.690751\n",
      "Epoch 00017 | Loss 0.7266 | Time(s) 1.8270 | Train_Accu 0.818182 | Test_Accu 0.768208\n",
      "Epoch 00018 | Loss 1.1748 | Time(s) 1.8609 | Train_Accu 0.809313 | Test_Accu 0.736416\n",
      "Epoch 00019 | Loss 1.7352 | Time(s) 1.9045 | Train_Accu 0.758315 | Test_Accu 0.677457\n",
      "Epoch 00020 | Loss 2.0094 | Time(s) 1.9116 | Train_Accu 0.718404 | Test_Accu 0.639306\n",
      "Epoch 00021 | Loss 1.5043 | Time(s) 1.9181 | Train_Accu 0.773836 | Test_Accu 0.702890\n",
      "Epoch 00022 | Loss 1.0522 | Time(s) 1.9322 | Train_Accu 0.813747 | Test_Accu 0.744509\n",
      "Epoch 00023 | Loss 0.7839 | Time(s) 1.9429 | Train_Accu 0.813747 | Test_Accu 0.749133\n",
      "Epoch 00024 | Loss 1.1538 | Time(s) 1.9528 | Train_Accu 0.793792 | Test_Accu 0.759538\n",
      "Epoch 00025 | Loss 1.4595 | Time(s) 1.9533 | Train_Accu 0.687361 | Test_Accu 0.716763\n",
      "Epoch 00026 | Loss 1.1991 | Time(s) 1.9542 | Train_Accu 0.789357 | Test_Accu 0.752601\n",
      "Epoch 00027 | Loss 0.8332 | Time(s) 1.9514 | Train_Accu 0.818182 | Test_Accu 0.756069\n",
      "Epoch 00028 | Loss 0.8258 | Time(s) 1.9470 | Train_Accu 0.824834 | Test_Accu 0.749133\n",
      "Epoch 00029 | Loss 1.0297 | Time(s) 1.9479 | Train_Accu 0.820399 | Test_Accu 0.749133\n",
      "Epoch 00030 | Loss 1.1292 | Time(s) 1.9443 | Train_Accu 0.804878 | Test_Accu 0.736416\n",
      "Epoch 00031 | Loss 1.0579 | Time(s) 1.9416 | Train_Accu 0.807095 | Test_Accu 0.742197\n",
      "Epoch 00032 | Loss 0.8483 | Time(s) 1.9461 | Train_Accu 0.820399 | Test_Accu 0.750867\n",
      "Epoch 00033 | Loss 0.6460 | Time(s) 1.9460 | Train_Accu 0.820399 | Test_Accu 0.764740\n",
      "Epoch 00034 | Loss 0.7677 | Time(s) 1.9427 | Train_Accu 0.802661 | Test_Accu 0.747399\n",
      "Epoch 00035 | Loss 0.9059 | Time(s) 1.9376 | Train_Accu 0.787140 | Test_Accu 0.750289\n",
      "Epoch 00036 | Loss 0.8177 | Time(s) 1.9330 | Train_Accu 0.789357 | Test_Accu 0.747399\n",
      "Epoch 00037 | Loss 0.5778 | Time(s) 1.9278 | Train_Accu 0.813747 | Test_Accu 0.753757\n",
      "Epoch 00038 | Loss 0.5961 | Time(s) 1.9232 | Train_Accu 0.829268 | Test_Accu 0.756647\n",
      "Epoch 00039 | Loss 0.8228 | Time(s) 1.9190 | Train_Accu 0.800443 | Test_Accu 0.712717\n",
      "Epoch 00040 | Loss 0.5651 | Time(s) 1.9149 | Train_Accu 0.835920 | Test_Accu 0.769942\n",
      "Epoch 00041 | Loss 0.5026 | Time(s) 1.9110 | Train_Accu 0.813747 | Test_Accu 0.759538\n",
      "Epoch 00042 | Loss 0.6811 | Time(s) 1.9074 | Train_Accu 0.773836 | Test_Accu 0.730058\n",
      "Epoch 00043 | Loss 0.5758 | Time(s) 1.9038 | Train_Accu 0.778271 | Test_Accu 0.731214\n",
      "Epoch 00044 | Loss 0.4643 | Time(s) 1.9010 | Train_Accu 0.831486 | Test_Accu 0.774566\n",
      "Epoch 00045 | Loss 0.6280 | Time(s) 1.8982 | Train_Accu 0.818182 | Test_Accu 0.735838\n",
      "Epoch 00046 | Loss 0.5114 | Time(s) 1.8955 | Train_Accu 0.829268 | Test_Accu 0.763006\n",
      "Epoch 00047 | Loss 0.4496 | Time(s) 1.8922 | Train_Accu 0.820399 | Test_Accu 0.759538\n",
      "Epoch 00048 | Loss 0.5669 | Time(s) 1.8896 | Train_Accu 0.787140 | Test_Accu 0.741618\n",
      "Epoch 00049 | Loss 0.4641 | Time(s) 1.8870 | Train_Accu 0.809313 | Test_Accu 0.749133\n",
      "Epoch 00050 | Loss 0.4380 | Time(s) 1.8845 | Train_Accu 0.829268 | Test_Accu 0.773410\n",
      "Epoch 00051 | Loss 0.5227 | Time(s) 1.8832 | Train_Accu 0.818182 | Test_Accu 0.746243\n",
      "Epoch 00052 | Loss 0.3945 | Time(s) 1.8805 | Train_Accu 0.842572 | Test_Accu 0.780347\n",
      "Epoch 00053 | Loss 0.4580 | Time(s) 1.8778 | Train_Accu 0.811530 | Test_Accu 0.763006\n",
      "Epoch 00054 | Loss 0.4561 | Time(s) 1.8755 | Train_Accu 0.818182 | Test_Accu 0.769364\n",
      "Epoch 00055 | Loss 0.3705 | Time(s) 1.8734 | Train_Accu 0.842572 | Test_Accu 0.778035\n",
      "Epoch 00056 | Loss 0.4620 | Time(s) 1.8715 | Train_Accu 0.822616 | Test_Accu 0.747977\n",
      "Epoch 00057 | Loss 0.3664 | Time(s) 1.8700 | Train_Accu 0.847007 | Test_Accu 0.775723\n",
      "Epoch 00058 | Loss 0.4189 | Time(s) 1.8676 | Train_Accu 0.824834 | Test_Accu 0.775723\n",
      "Epoch 00059 | Loss 0.4020 | Time(s) 1.8652 | Train_Accu 0.831486 | Test_Accu 0.775145\n",
      "Epoch 00060 | Loss 0.3658 | Time(s) 1.8637 | Train_Accu 0.842572 | Test_Accu 0.772254\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6700032 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-422a92bfacfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#pred_prob = net.forward(graph_train, train_feature)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#loss = criterion(pred_prob,train_label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mpred_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_whole\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhole_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mtrain_accu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhole_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtest_accu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhole_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a04248c2abd7>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, g, features)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a04248c2abd7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, features)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\acaconda\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a04248c2abd7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, feature)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgcn_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_mod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\acaconda\\envs\\pytorch_gpu\\lib\\site-packages\\dgl\\graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[1;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[0;32m   2745\u001b[0m                                           \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m                                           apply_func=apply_node_func)\n\u001b[1;32m-> 2747\u001b[1;33m             \u001b[0mRuntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2749\u001b[0m     def prop_nodes(self,\n",
      "\u001b[1;32mD:\\acaconda\\envs\\pytorch_gpu\\lib\\site-packages\\dgl\\runtime\\runtime.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(prog)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;31m# prog.pprint_exe(exe)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mexe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\acaconda\\envs\\pytorch_gpu\\lib\\site-packages\\dgl\\runtime\\ir\\executor.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m         self.ret.data = F.copy_reduce(\n\u001b[0;32m   1199\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreducer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m             out_map)\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\acaconda\\envs\\pytorch_gpu\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[0;32m    366\u001b[0m     def forward(ctx, reducer, graph, target, in_data, out_size, in_map,\n\u001b[0;32m    367\u001b[0m                 out_map):\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0mout_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m         \u001b[0min_data_nd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzerocopy_to_dgl_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mout_data_nd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzerocopy_to_dgl_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6700032 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-5)\n",
    "dur = []\n",
    "for epoch in range(200):\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    pred_prob = net.forward(graph_whole, whole_feature)\n",
    "    loss = criterion(pred_prob[train_mask],whole_label[train_mask])\n",
    "    \n",
    "    #pred_prob = net.forward(graph_train, train_feature)\n",
    "    #loss = criterion(pred_prob,train_label)\n",
    "    pred_label = net.predict(graph_whole, whole_feature)\n",
    "    train_accu = accuracy_score(pred_label[train_mask],whole_label[train_mask])\n",
    "    test_accu = accuracy_score(pred_label[test_mask],whole_label[test_mask])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    dur.append(time.time() - t0)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Train_Accu {:4f} | Test_Accu {:4f}\".format(\n",
    "        epoch, loss.item(), np.mean(dur), train_accu,test_accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#玩具数据集用以检验图结构生成的准确率。\n",
    "#测试发现difflib的相似度量是字符级的\n",
    "'''\n",
    "dataframe = pd.DataFrame([\n",
    "        [\"a\", \"111222\", \"computer Science\", \"bruce\"],\n",
    "        [\"b\", \"111222\", \"computer Science\", \"Bruce Lee\"],\n",
    "        [\"c\", \"111222\", \"computer Science\", \"mike ,john\"],\n",
    "        [\"a\", \"111223\", \"Hassdsdsaad\", \"kkl\"],\n",
    "        [\"d\", \"111223\", \"Hassdsdaaad\", \"kkkl\"],\n",
    "        [\"c\", \"111224\", \"asdfgh\", \"zxcr\"]\n",
    "    ],\n",
    "    columns=[\"source\", \"isbn\", \"name\", \"author\"]\n",
    ")\n",
    "g = generate_DGLGraph(dataframe)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_gpu]",
   "language": "python",
   "name": "conda-env-pytorch_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
